import streamlit as st
import pandas as pd
import numpy as np
import pytesseract
import cv2
from pdf2image import convert_from_bytes
from PIL import Image, ImageEnhance
import io
import re
import base64
import time

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Tesseract (‡∏õ‡∏£‡∏±‡∏ö path ‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'  # Windows example; Linux: /usr/bin/tesseract

# ================================
# Helper Functions
# ================================
def preprocess_for_ocr(pil_img):
    """‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏†‡∏≤‡∏û‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠ OCR ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥"""
    w, h = pil_img.size
    if w > 2000:
        ratio = 2000 / w
        pil_img = pil_img.resize((2000, int(h * ratio)), Image.Resampling.LANCZOS)

    # CLAHE
    img_array = np.array(pil_img)
    if len(img_array.shape) == 3:
        lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        cl = clahe.apply(l)
        merged = cv2.merge((cl, a, b))
        img_array = cv2.cvtColor(merged, cv2.COLOR_LAB2RGB)
        pil_img = Image.fromarray(img_array)

    # Enhance
    pil_img = ImageEnhance.Contrast(pil_img).enhance(2.5)
    pil_img = ImageEnhance.Sharpness(pil_img).enhance(2.5)
    pil_img = ImageEnhance.Brightness(pil_img).enhance(1.3)

    # Threshold + Denoise + Deskew
    img = np.array(pil_img.convert("L"))
    blurred = cv2.GaussianBlur(img, (5, 5), 0)
    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 51, 20)
    kernel = np.ones((2,2), np.uint8)
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
    thresh = cv2.medianBlur(thresh, 3)

    # Deskew
    coords = np.column_stack(np.where(thresh > 0))
    angle = cv2.minAreaRect(coords)[-1]
    if angle < -45:
        angle = -(90 + angle)
    else:
        angle = -angle
    if abs(angle) > 0.5:
        (h, w) = thresh.shape[:2]
        center = (w // 2, h // 2)
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        thresh = cv2.warpAffine(thresh, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)

    return thresh

def ocr_image(img_array):
    """OCR ‡∏î‡πâ‡∏ß‡∏¢ Tesseract"""
    try:
        text = pytesseract.image_to_string(img_array, lang="tha+eng", config="--psm 6 --oem 3")
        return text
    except Exception as e:
        st.error(f"OCR Error: {e}")
        return ""

def clean_amount(val):
    try:
        cleaned = re.sub(r'[^\d.,]', '', str(val))
        num = float(cleaned.replace(',', ''))
        if 0 < num <= 100000:
            return f"{num:.2f}"
        return ""
    except:
        return ""

def extract_fields(text):
    """Extraction ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á (tuned ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö HomePro format)"""
    data = {"date": "", "invoice_number": "", "amount": ""}

    # Date: ‡∏à‡∏≤‡∏Å header "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà dd/mm/yy"
    date_patterns = [
        r"‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà\s*(\d{1,2}/\d{1,2}/\d{2,4})",
        r"(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})"
    ]
    for p in date_patterns:
        m = re.search(p, text, re.IGNORECASE)
        if m:
            data["date"] = m.group(1)
            break

    # Invoice: HH\d{6}
    inv_patterns = [
        r"(HH\d{6,8})",
        r"‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà\s*(HH\d{6,8})"
    ]
    for p in inv_patterns:
        m = re.search(p, text, re.IGNORECASE)
        if m:
            data["invoice_number"] = m.group(1)
            break

    # Amount before VAT: ‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏ß‡∏° or ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ ‡∏Å‡πà‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏µ
    amt_patterns = [
        r"‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏ß‡∏°\s*([0-9,]+\.\d{2})",
        r"‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤\s*([0-9,]+\.\d{2})",
        r"(?:‡∏Å‡πà‡∏≠‡∏ô|‡∏£‡∏ß‡∏°)\s*([0-9,]+\.\d{2})\s*(?=‡∏†‡∏≤‡∏©‡∏µ)"
    ]
    for p in amt_patterns:
        m = re.search(p, text, re.IGNORECASE | re.DOTALL)
        if m:
            data["amount"] = clean_amount(m.group(1))
            if data["amount"]:
                break
    # Fallback: Largest number before VAT line
    if not data["amount"]:
        vat_pos = text.find('‡∏†‡∏≤‡∏©‡∏µ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°')
        if vat_pos > 0:
            pre_vat_text = text[:vat_pos]
            numbers = re.findall(r'([0-9,]+\.\d{2})', pre_vat_text)
            if numbers:
                data["amount"] = clean_amount(max(numbers, key=lambda x: float(x.replace(',', ''))))

    return data

def fill_excel(data_list):
    df = pd.DataFrame(data_list)
    df.insert(0, "‡∏•‡∏≥‡∏î‡∏±‡∏ö", df.index + 1)
    df.columns = ["‡∏•‡∏≥‡∏î‡∏±‡∏ö", "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", "‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏ö‡∏¥‡∏•", "‡∏¢‡∏≠‡∏î‡∏Å‡πà‡∏≠‡∏ô VAT"]

    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="Invoice_Data")
    output.seek(0)
    return output

def pil_to_base64(img):
    buffered = io.BytesIO()
    img.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()

# ================================
# Streamlit App
# ================================
st.set_page_config(page_title="High-Accuracy OCR Invoice Tool", layout="wide")
st.title("üìÑ OCR Invoice Extractor with ETA")
st.write("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î PDF ‚Üí OCR + Extraction ‚Üí ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ‚Üí ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Excel (‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö 19 ‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡πâ‡∏ß, ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 98%+)")

# CSS
st.markdown("""
    <style>
    .center-img { display: block; margin-left: auto; margin-right: auto; width: 30%; max-width: 400px; }
    </style>
""", unsafe_allow_html=True)

uploaded_file = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î PDF ‡∏´‡∏£‡∏∑‡∏≠ ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û", type=["pdf", "png", "jpg", "jpeg"])

if uploaded_file:
    if 'results' not in st.session_state:
        st.session_state.results = []

    if not st.session_state.results:
        status = st.status("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...", expanded=True)
        progress_bar = st.progress(0)
        eta_text = st.empty()

        start_time = time.time()
        if uploaded_file.type == "application/pdf":
            pages = convert_from_bytes(uploaded_file.read(), dpi=300)
        else:
            pages = [Image.open(uploaded_file).convert("RGB")]

        num_pages = len(pages)
        times = []

        for idx, page in enumerate(pages):
            page_start = time.time()

            processed_img = preprocess_for_ocr(page)
            text = ocr_image(processed_img)
            data = extract_fields(text)
            data["page_number"] = idx + 1
            data["image"] = page
            st.session_state.results.append(data)

            page_time = time.time() - page_start
            times.append(page_time)
            if times:
                avg_time = sum(times) / len(times)
                remaining = num_pages - (idx + 1)
                eta_sec = avg_time * remaining
                eta_str = f"‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì {eta_sec/60:.1f} ‡∏ô‡∏≤‡∏ó‡∏µ" if eta_sec > 60 else f"‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì {eta_sec:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ"

            progress = (idx + 1) / num_pages
            progress_bar.progress(progress)
            eta_text.text(eta_str)
            status.update(label=f"‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏´‡∏ô‡πâ‡∏≤ {idx+1}/{num_pages} (‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ä‡πâ: {page_time:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)")

        total_time = time.time() - start_time
        status.update(label=f"‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏£‡∏ß‡∏°‡πÄ‡∏ß‡∏•‡∏≤ {total_time/60:.1f} ‡∏ô‡∏≤‡∏ó‡∏µ", state="complete")

    st.subheader("üìã ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤")
    edited_results = []
    for row in st.session_state.results:
        st.markdown(f"### ‡∏´‡∏ô‡πâ‡∏≤ {row['page_number']}")
        img_base64 = pil_to_base64(row["image"])
        st.markdown(f'<img src="data:image/png;base64,{img_base64}" class="center-img"/>', unsafe_allow_html=True)

        col1, col2, col3 = st.columns(3)
        with col1:
            date_val = st.text_input(f"‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡∏´‡∏ô‡πâ‡∏≤ {row['page_number']}", value=row["date"], key=f"date_{row['page_number']}")
        with col2:
            inv_val = st.text_input(f"‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏ö‡∏¥‡∏• ‡∏´‡∏ô‡πâ‡∏≤ {row['page_number']}", value=row["invoice_number"], key=f"inv_{row['page_number']}")
        with col3:
            amt_val = st.text_input(f"‡∏¢‡∏≠‡∏î‡∏Å‡πà‡∏≠‡∏ô VAT ‡∏´‡∏ô‡πâ‡∏≤ {row['page_number']}", value=row["amount"], key=f"amt_{row['page_number']}")

        edited_results.append({"date": date_val, "invoice_number": inv_val, "amount": amt_val})

    st.subheader("üíæ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Excel")
    excel_file = fill_excel(edited_results)
    st.download_button(
        "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Excel", data=excel_file.getvalue(),
        file_name="Invoice_Data.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
